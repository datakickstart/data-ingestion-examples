{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "database = \"StackOverflow2010\"\r\n",
        "db_host_name = \"sandbox-2-sqlserver.database.windows.net\"\r\n",
        "db_url = f\"jdbc:sqlserver://{db_host_name};databaseName={database}\"\r\n",
        "db_user = mssparkutils.credentials.getSecretWithLS(\"demokv\", \"sql-user-stackoverflow\")\r\n",
        "db_password = mssparkutils.credentials.getSecretWithLS(\"demokv\", \"sql-pwd-stackoverflow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "spark.sql(f\"CREATE DATABASE IF NOT EXISTS raw_stackoverflow LOCATION '/demo/raw_stackoverflow'\")\r\n",
        "table_list = [\"Badges\", \"Comments\", \"LinkTypes\", \"PostLinks\", \"Posts\", \"PostTypes\", \"Users\", \"Votes\", \"VoteTypes\"]\r\n",
        "\r\n",
        "def load_table(table):\r\n",
        "    print(table)\r\n",
        "    destination_table = \"raw_stackoverflow.\" + table\r\n",
        "\r\n",
        "    df = (\r\n",
        "        spark.read\r\n",
        "        .format(\"com.microsoft.sqlserver.jdbc.spark\")\r\n",
        "        .option(\"url\", db_url)\r\n",
        "        .option(\"dbtable\", table)\r\n",
        "        .option(\"user\", db_user)\r\n",
        "        .option(\"password\", db_password)\r\n",
        "        .load()\r\n",
        "    )\r\n",
        "\r\n",
        "    df.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(destination_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {},
      "source": [
        "from threading import Thread\r\n",
        "from queue import Queue\r\n",
        "\r\n",
        "q = Queue()\r\n",
        "\r\n",
        "worker_count = 2\r\n",
        "\r\n",
        "def run_tasks(function, q):\r\n",
        "    while not q.empty():\r\n",
        "        value = q.get()\r\n",
        "        function(value)\r\n",
        "        q.task_done()\r\n",
        "\r\n",
        "\r\n",
        "print(table_list)\r\n",
        "\r\n",
        "for table in table_list:\r\n",
        "    q.put(table)\r\n",
        "\r\n",
        "for i in range(worker_count):\r\n",
        "    t=Thread(target=run_tasks, args=(load_table, q))\r\n",
        "    t.daemon = True\r\n",
        "    t.start()\r\n",
        "\r\n",
        "print(\"Running load\")\r\n",
        "q.join()\r\n",
        "print(\"Load completed\")\r\n",
        ""
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}
